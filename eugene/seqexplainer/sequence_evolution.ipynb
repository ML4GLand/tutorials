{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence evolution walkthrough\n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *07/16/2023*)\n",
    "***\n",
    "**Description:**\n",
    "This notebook is meant to serve as a guide for performing an *in silico* evolution analysis with a trained PyTorch model using SeqExplainer. The notebook will walk through the steps of performing the analysis and interpreting the results.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Generating functional DNA sequences is a huge research area in synthetic biology. From controlling plant behavior to , the possibilities are huge. Machine learning models offer signfiicant promise as a tool for generating functional sequences, but this area is still new. With SeqExplainer, we aim to give users tools for exploring the sequence space around a trained model. We implement the simplest form of this approach that iteratively evolves a sequence by greedily inserting the mutation with the largest predicted impact at each iteration. Starting with an initial sequence (e.g. random, shuffled, etc.), this strategy can be used to evolve synthetic functional sequences. This style of analysis is a promising direction for further research, and can also serve as an extension of ISM for validating that the model has learned representations that resemble motifs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an *in silico* evolution\n",
    "Let's run an evolution on the model trained in the EUGENe paper for prediction of the regulatory activity of plant promoters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend cloning the entire tutorials repository so that you have all the necessary intermediate files you need, but when applicable, we also provide links to download the files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to where you would like to save all your results, likely your tutorials download directory\n",
    "import os\n",
    "os.chdir(\"/cellar/users/aklie/projects/ML4GLand/tutorials\")  # TODO: change this to your own directory\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment and run the following to get the model and config. You will not need to do this if you are working in your cloned tutorials repo\n",
    "#!mkdir -p $cwd/models\n",
    "#!wget https://github.com/ML4GLand/tutorials/raw/main/models/jores21_cnn_leaf.ckpt -O $cwd/models/jores21_cnn_leaf.ckpt\n",
    "\n",
    "#!mkdir -p $cwd/configs\n",
    "#!wget https://raw.githubusercontent.com/ML4GLand/tutorials/main/configs/cnn.yaml -O $cwd/configs/cnn.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in a model\n",
    " - TODO: Make the model checkpoint available somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General purpose imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the model form the checkpoint\n",
    "model_file = \"models/jores21_cnn_leaf.ckpt\"\n",
    "model_arch = models.load_config(config_path=\"configs/cnn.yaml\")\n",
    "model = models.SequenceModule.load_from_checkpoint(model_file, arch=model_arch.arch)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some random sequences\n",
    "We next need to create the sequences we want to evolve. In this notebook, we will generate random sequences as our starting material. We can use SeqPro functions to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seqpro as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 sequences of length 170\n",
    "random_seqs = sp.random_seqs(\n",
    "    shape=(10, 170),\n",
    "    alphabet=sp.alphabets.DNA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the sequences\n",
    "random_seqs = sp.ohe(random_seqs, alphabet=sp.alphabets.DNA).transpose(0, 2, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the evolution\n",
    "Now that we have some baseline sequences, we can perform the evolution. This is done by iteratively performing a *in silico* saturation mutagenesis and selecting the mutation that most increases the predicted activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqexplainer import evolution\n",
    "from tqdm.auto import tqdm  # progress bar to use for evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 2 minutes to do 5 rounds of evolution on 10 sequences\n",
    "rounds = 5\n",
    "evolved_seqs = []\n",
    "deltas = np.zeros((len(random_seqs), rounds))\n",
    "mutation_pos = []\n",
    "for i, random_seq in tqdm(enumerate(random_seqs), total=random_seqs.shape[0], desc=\"Evolving sequences\"):\n",
    "    evolved_res = evolution(\n",
    "        model=model,\n",
    "        X=random_seq,\n",
    "        rounds=rounds,\n",
    "    )\n",
    "    evolved_seqs.append(evolved_res[0])\n",
    "    deltas[i, :] = deltas[i, :] + evolved_res[1]\n",
    "    mutation_pos.append(evolved_res[2])\n",
    "X_evolved = torch.tensor(np.array(evolved_seqs), dtype=torch.float32)\n",
    "mutation_pos = np.array(mutation_pos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the score change over rounds\n",
    "Let's visualize the results by plotting the violin plots predicted activities over each round of evolution. The easiest way to do this is to first create a dataframe with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores[0] = model.predict(random_seqs, batch_size=32, verbose=False).detach().cpu().numpy().squeeze()\n",
    "for i in range(1, rounds+1):\n",
    "    scores[i] = scores[i-1] + deltas[:, i-1]\n",
    "score_df = pd.DataFrame(scores)\n",
    "score_df.columns = [\"round_{}\".format(i) for i in range(rounds+1)]\n",
    "score_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily plot with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a violinplot of the scores at each round\n",
    "g = sns.violinplot(data=score_df, color=\"lightblue\")\n",
    "g.set_xlabel(\"Round\")\n",
    "g.set_ylabel(\"Score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the differences in attribution logos\n",
    "Another interesting visualization one can use is to plot the before and after attrribution logos. This allows us to see what features are being selected for by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqexplainer import attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the attributions for the random and evolved sequences\n",
    "random_attrs = attribute(\n",
    "    model=model,\n",
    "    inputs=random_seqs,\n",
    "    method=\"InputXGradient\",\n",
    ")\n",
    "evolved_attrs = attribute(\n",
    "    model=model,\n",
    "    inputs=X_evolved,\n",
    "    method=\"InputXGradient\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the attribution logos using logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import logomaker as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complicated plotting that we will eventually turn into a built in function\n",
    "for i in tqdm(range(len(random_attrs)), desc=\"Plotting\", total=len(random_attrs)):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 4))\n",
    "    random_viz_seq = pd.DataFrame(random_attrs[i].T, columns=[\"A\", \"C\", \"G\", \"T\"])\n",
    "    random_viz_seq.index.name = \"pos\"\n",
    "    random_logo = lm.Logo(random_viz_seq, color_scheme=\"classic\", figsize=(10, 2), ax=ax[0])\n",
    "    random_logo.style_spines(visible=False)\n",
    "    random_logo.style_spines(spines=['left'], visible=True)\n",
    "    random_logo.ax.set_xticks([])\n",
    "    ax[0].set_title(f\"{scores[0][i].item():.2f} -> {scores[5][i].item():.2f}\")\n",
    "    ax_bottom = ax[0].get_ylim()[0]\n",
    "    evolved_viz_seq = pd.DataFrame(evolved_attrs[i].T, columns=[\"A\", \"C\", \"G\", \"T\"])\n",
    "    evolved_viz_seq.index.name = \"pos\"\n",
    "    evolved_logo = lm.Logo(evolved_viz_seq, color_scheme=\"classic\", figsize=(10, 2), ax=ax[1])\n",
    "    evolved_logo.style_spines(visible=False)\n",
    "    evolved_logo.style_spines(spines=['left'], visible=True)\n",
    "    evolved_logo.ax.set_xticks([])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly for this model, we see that it tries to select for the presence of the TATA box in almost every case (even when one already exists). And it doesn't even seem to care if it puts them only a few nucleotides apart."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding overinterpretation\n",
    "Sequence evolution represents abother means for intepreting what features a model is learning to use to make predictions and represents an exxciting avenue for exploration. As a newer method, one should also be aware that theoretical properties of prediction evolution are not well understood and should be investigated. We hope SeqExplainer provides a useful tool for exploring this area."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
